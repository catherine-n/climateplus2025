{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9f87cea",
   "metadata": {},
   "source": [
    "**Configuration** <br>\n",
    "* Single Class : PV_all\n",
    "* Learning rate : lr0=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8a5335",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_content = \"\"\"\n",
    "path: /home/il72/cape_town_year_of_installation/datasets/pv_capetown_after_qc_5K\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "\n",
    "names:\n",
    "  0: PV_all\n",
    "\"\"\"\n",
    "\n",
    "with open(\"/home/il72/cape_town_year_of_installation/YOLO_CapeTown_5K_single_categories(July_14)/data.yml\", \"w\") as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(\"data.yml (with path) created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101172cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Clear CUDA cache and set GPU (0 or 1)\n",
    "import os\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "print(\"Using device:\", torch.cuda.get_device_name(0)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dab561d",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac8251e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your pretrained model\n",
    "# model = YOLO(\"yolo11x.pt\")  # you already have this file\n",
    "# model = YOLO(\"yolo11x-obb.pt\")\n",
    "model = YOLO(\"yolo11x-obb.pt\")\n",
    "\n",
    "# Train with your own dataset\n",
    "model.train(\n",
    "    data=\"/home/il72/cape_town_year_of_installation/YOLO_CapeTown_5K_single_categories(July_14)/data.yml\",  # your dataset config file\n",
    "    task=\"obb\",\n",
    "    epochs=100,                    # or any number that fits your case 100\n",
    "    imgsz=1024,                     # image size, Must corresponds with input image size\n",
    "    device=0,                      # mps for Mac, 0 for \n",
    "    batch=2,                      # adjust depending on your VRAM\n",
    "    lr0=0.0001,                # initial learning rate\n",
    "    name=\"pv_detection_5K_yolo11x_obb_single_class_lr0.0001\"    # experiment name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f508d",
   "metadata": {},
   "source": [
    "Evaluaton (Generating `.txt` for visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de8972d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.157 ðŸš€ Python-3.10.12 torch-2.7.1+cu126 CUDA:0 (NVIDIA GeForce RTX 3080, 10001MiB)\n",
      "YOLO11x-obb summary (fused): 199 layers, 58,736,758 parameters, 0 gradients, 202.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 6100.6Â±3745.8 MB/s, size: 3075.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /data/users/il72/cape_town_year_of_installation/datasets/pv_capetown_after_qc_5K/labels/test.cache... 249 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 249/249 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:12<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        249       1136      0.836      0.798      0.825      0.703\n",
      "Speed: 1.2ms preprocess, 38.4ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/obb/val6\u001b[0m\n",
      "Test Evaluation Results:\n",
      "mAP@0.5: 0.8249\n",
      "mAP@0.5:0.95: 0.7032\n",
      "\n",
      "Per-class metrics:\n",
      "0 -> Precision: 0.8359, Recall: 0.7981, mAP@0.5: 0.7032\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Manually set CUDA device to GPU 1\n",
    "torch.cuda.set_device(1)\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load your trained model (not the base pretrained model!)\n",
    "model = YOLO(\"/home/il72/cape_town_year_of_installation/YOLO_CapeTown_5K_single_categories(July_14)/runs/obb/pv_detection_5K_yolo11x_obb_single_class_lr0.0001/weights/best.pt\")\n",
    "\n",
    "# Run evaluation on test set with proper data config\n",
    "results = model.val(\n",
    "    data=\"/home/il72/cape_town_year_of_installation/YOLO_CapeTown_5K_single_categories(July_14)/data.yml\",\n",
    "    split=\"test\",\n",
    "    task=\"obb\",  # Make sure it runs in oriented bounding box mode\n",
    "    save=True,          # Save prediction visualizations\n",
    "    save_txt=True,      # Save prediction coordinates\n",
    "    save_conf=True      # Save confidence values (important for analysis)\n",
    ")\n",
    "\n",
    "# Print summary metrics\n",
    "print(\"Test Evaluation Results:\")\n",
    "print(f\"mAP@0.5: {results.box.map50:.4f}\")\n",
    "print(f\"mAP@0.5:0.95: {results.box.map:.4f}\")\n",
    "\n",
    "# Per-class metrics\n",
    "print(\"\\nPer-class metrics:\")\n",
    "for i, class_name in enumerate(results.names):\n",
    "    print(f\"{class_name} -> Precision: {results.box.p[i]:.4f}, Recall: {results.box.r[i]:.4f}, mAP@0.5: {results.box.maps[i]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

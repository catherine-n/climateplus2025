{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5254d56",
   "metadata": {},
   "source": [
    "- This script reconstructs full-size segmentation masks (12500 * 12500) from U-Net predictions generated from 320×320 crops centered on YOLO-detected centroids. \n",
    "\n",
    "- Read YOLO detection results and tile metadata(csv), which are used to map each local centroid back to global image coordinates. For each centroid, the corresponding U-Net prediction (stored in a .json file) is loaded and correctly aligned within the full-size canvas, accounting for tile offsets and boundary clipping. \n",
    "\n",
    "- To ensure accurate merging, only valid predicted regions within tile boundaries are pasted, and overlapping regions are resolved using np.maximum() — retaining the highest class index when overlaps occur. <br>\n",
    "\n",
    "- **Note**\n",
    "The class index ordering(based on Precision per class) is:\n",
    "    - 0 = background, 1 = solar panel, 2 = pool heater, 3 = water heater.\n",
    "- The output is a single .png mask per base image(12500 * 12500 size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fba94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading YOLO CSV and tile metadata...\n",
      "\n",
      "▶ Reconstructing mask for: 2023_RGB_8cm_W24A_17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/390 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 390/390 [01:12<00:00,  5.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /shared/data/climateplus2025/YOLO+U-Net_Prediction_updated_0722/reconstructed_prediction_masks_12500/reconstructed_mask_2023_RGB_8cm_W24A_17.png\n",
      "\n",
      "▶ Reconstructing mask for: 2023_RGB_8cm_W25C_16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 178/178 [00:42<00:00,  4.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /shared/data/climateplus2025/YOLO+U-Net_Prediction_updated_0722/reconstructed_prediction_masks_12500/reconstructed_mask_2023_RGB_8cm_W25C_16.png\n",
      "\n",
      "▶ Reconstructing mask for: 2023_RGB_8cm_W57B_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [00:54<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /shared/data/climateplus2025/YOLO+U-Net_Prediction_updated_0722/reconstructed_prediction_masks_12500/reconstructed_mask_2023_RGB_8cm_W57B_8.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============================\n",
    "# CONFIGURATION\n",
    "# ============================\n",
    "yolo_csv_path = \"/shared/data/climateplus2025/Prediction_for_poster_July21/processed_centroids_and_bbox.csv\"\n",
    "tile_meta_csv = \"/shared/data/climateplus2025/Prediction_for_poster_July21/tile_metadata_for_reconstruction.csv\"\n",
    "# !!! refer to second code chunk in 0.Data_Processing.ipynb in Prediction_for_poster_July21 folder !!!\n",
    "unet_pred_mask_dir = \"/home/cmn60/cape_town_segmentation/prediction_outputs_v42\" #v40 : U-Net only, # v42 : YOLO+U-Net # 48 : U-Net only(only predicted value)\n",
    "# In Catherine's code there are predicted value and Ground Truth (GT) masks together\n",
    "original_image_shape = (12500, 12500)  # Full image size\n",
    "output_dir = \"/shared/data/climateplus2025/YOLO+U-Net_Prediction_updated_0722/reconstructed_prediction_masks_12500\"\n",
    "tile_crop_size = 320\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ============================\n",
    "# UTILITY FUNCTIONS\n",
    "# ============================\n",
    "def load_json_pred_mask(json_path):\n",
    "    \"\"\"\n",
    "    Reads prediction JSON file and returns a 320x320 class-indexed mask,\n",
    "    using ONLY 'predicted_coords'. Ground truth data is ignored.\n",
    "    \"\"\"\n",
    "    with open(json_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    pred_coords = data.get(\"predicted_coords\", {})\n",
    "    mask = np.zeros((tile_crop_size, tile_crop_size), dtype=np.uint8)\n",
    "\n",
    "    # Class label mapping — must match your model output ordering\n",
    "    class_order = [\"background\", \"PV_normal\", \"PV_pool\", \"PV_heater\"]\n",
    "\n",
    "    for class_idx, cls_name in enumerate(class_order):\n",
    "        coords = pred_coords.get(cls_name, [])\n",
    "        for y, x in coords:\n",
    "            # Protect against malformed coordinates\n",
    "            if 0 <= y < tile_crop_size and 0 <= x < tile_crop_size:\n",
    "                mask[y, x] = class_idx\n",
    "\n",
    "    return mask\n",
    "\n",
    "# ============================\n",
    "# LOAD CSVs\n",
    "# ============================\n",
    "print(\"Loading YOLO CSV and tile metadata...\")\n",
    "df = pd.read_csv(yolo_csv_path)\n",
    "tile_meta_df = pd.read_csv(tile_meta_csv)\n",
    "tile_meta_df.set_index(\"tile_name\", inplace=True)\n",
    "\n",
    "# Group by base image\n",
    "df[\"base_image_name\"] = df[\"image_name\"].apply(lambda x: x.split(\"_tile_\")[0])\n",
    "grouped = df.groupby(\"base_image_name\")\n",
    "\n",
    "# ============================\n",
    "# MAIN PROCESSING LOOP\n",
    "# ============================\n",
    "for base_image_name, group_df in grouped:\n",
    "    print(f\"\\n▶ Reconstructing mask for: {base_image_name}\")\n",
    "\n",
    "    full_pred_mask = np.zeros(original_image_shape, dtype=np.uint8)\n",
    "\n",
    "    for idx, row in tqdm(group_df.iterrows(), total=len(group_df)):\n",
    "        pred_id = row[\"prediction_id\"]\n",
    "        image_name = row[\"image_name\"]\n",
    "        centroid_str = row[\"pixel_centroid\"]\n",
    "\n",
    "        # 1. Load tile metadata\n",
    "        if image_name not in tile_meta_df.index:\n",
    "            print(f\"[Warning] Missing metadata: {image_name}\")\n",
    "            continue\n",
    "\n",
    "        tile_info = tile_meta_df.loc[image_name]\n",
    "        tile_x = int(tile_info[\"tile_x\"])\n",
    "        tile_y = int(tile_info[\"tile_y\"])\n",
    "        tile_w = int(tile_info[\"tile_width\"])\n",
    "        tile_h = int(tile_info[\"tile_height\"])\n",
    "\n",
    "        # 2. Parse centroid\n",
    "        try:\n",
    "            cx, cy = eval(centroid_str)\n",
    "            cx, cy = int(round(cx)), int(round(cy))\n",
    "        except:\n",
    "            print(f\"[Warning] Invalid centroid at row {idx}\")\n",
    "            continue\n",
    "\n",
    "        # 3. Global coordinates of center\n",
    "        global_cx = tile_x + cx\n",
    "        global_cy = tile_y + cy\n",
    "\n",
    "        # 4. Define crop box in global coordinates\n",
    "        x1 = global_cx - tile_crop_size // 2\n",
    "        y1 = global_cy - tile_crop_size // 2\n",
    "        x2 = x1 + tile_crop_size\n",
    "        y2 = y1 + tile_crop_size\n",
    "\n",
    "        # 5. Clip to full image boundaries\n",
    "        x1_clip = max(0, x1)\n",
    "        y1_clip = max(0, y1)\n",
    "        x2_clip = min(original_image_shape[1], x2)\n",
    "        y2_clip = min(original_image_shape[0], y2)\n",
    "\n",
    "        w = x2_clip - x1_clip\n",
    "        h = y2_clip - y1_clip\n",
    "        if w <= 0 or h <= 0:\n",
    "            continue\n",
    "\n",
    "        x_offset = x1_clip - x1\n",
    "        y_offset = y1_clip - y1\n",
    "\n",
    "        # 6. Load prediction mask\n",
    "        if not pred_id.startswith(\"i_\"):\n",
    "            pred_id = \"i_\" + pred_id\n",
    "\n",
    "        json_path = os.path.join(unet_pred_mask_dir, f\"{pred_id}.json\")\n",
    "        if not os.path.exists(json_path):\n",
    "            print(f\"[Warning] Missing JSON: {json_path}\")\n",
    "            continue\n",
    "\n",
    "        pred_mask = load_json_pred_mask(json_path)\n",
    "\n",
    "        # 7. Crop only valid region\n",
    "        x_crop_end = min(x_offset + w, tile_w)\n",
    "        y_crop_end = min(y_offset + h, tile_h)\n",
    "        pred_crop = pred_mask[y_offset:y_crop_end, x_offset:x_crop_end]\n",
    "\n",
    "        # 8. Paste into full image\n",
    "        full_pred_mask[y1_clip:y1_clip + pred_crop.shape[0], x1_clip:x1_clip + pred_crop.shape[1]] = np.maximum(\n",
    "            full_pred_mask[y1_clip:y1_clip + pred_crop.shape[0], x1_clip:x1_clip + pred_crop.shape[1]],\n",
    "            pred_crop\n",
    "        )\n",
    "\n",
    "    # Save result\n",
    "    output_path = os.path.join(output_dir, f\"reconstructed_mask_{base_image_name}.png\")\n",
    "    cv2.imwrite(output_path, full_pred_mask)\n",
    "    print(f\"Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba509879",
   "metadata": {},
   "source": [
    "The output above is a single large prediction mask image (12,500 × 12,500). However, our ground truth (GT) labels were already generated during the U-Net pipeline as cropped 320 × 320 images.\n",
    "\n",
    "Therefore, we need to crop the large prediction mask into 320 × 320 patches and match them with the corresponding ground truth files.\n",
    "The file names must match those used in the U-Net ground truth mask folder.\n",
    "For example: m_xxx_xxx format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "463f53c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:06<00:00,  2.33s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# CONFIGURATION\n",
    "reconstructed_mask_dir = \"/shared/data/climateplus2025/YOLO+U-Net_Prediction_updated_0722/reconstructed_prediction_masks\"\n",
    "tile_size = 320\n",
    "tile_output_dir = \"/shared/data/climateplus2025/YOLO+U-Net_Prediction_updated_0722/prediction_masks_tiles_320\"\n",
    "\n",
    "os.makedirs(tile_output_dir, exist_ok=True)\n",
    "\n",
    "# LOOP OVER MASKS\n",
    "for filename in tqdm(os.listdir(reconstructed_mask_dir)):\n",
    "    if not filename.endswith(\".png\"):\n",
    "        continue\n",
    "\n",
    "    base_name = filename.replace(\"reconstructed_mask_\", \"\").replace(\".png\", \"\")\n",
    "    mask_path = os.path.join(reconstructed_mask_dir, filename)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)  # Read as grayscale or multi-class\n",
    "\n",
    "    height, width = mask.shape[:2]\n",
    "\n",
    "    # Calculate padding (if needed)\n",
    "    pad_h = (tile_size - height % tile_size) % tile_size\n",
    "    pad_w = (tile_size - width % tile_size) % tile_size\n",
    "    padded_mask = np.pad(mask, ((0, pad_h), (0, pad_w)), mode='constant')\n",
    "\n",
    "    padded_height, padded_width = padded_mask.shape\n",
    "\n",
    "    # Tile loop\n",
    "    for y in range(0, padded_height, tile_size):\n",
    "        for x in range(0, padded_width, tile_size):\n",
    "            tile = padded_mask[y:y+tile_size, x:x+tile_size]\n",
    "\n",
    "            # Skip blank masks\n",
    "            if np.all(tile == 0):\n",
    "                continue\n",
    "\n",
    "            row_idx = y // tile_size\n",
    "            col_idx = x // tile_size\n",
    "\n",
    "            out_filename = f\"m_{base_name}_{row_idx}_{col_idx}.png\"\n",
    "            out_path = os.path.join(tile_output_dir, out_filename)\n",
    "\n",
    "            cv2.imwrite(out_path, tile)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

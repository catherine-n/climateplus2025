{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67595c09",
   "metadata": {},
   "source": [
    "This script evaluates the performance of the YOLO + U-Net model using IoU, Precision, and Recall per class.\n",
    "\n",
    "**Note:**\n",
    "Unlike evaluations based on YOLO-cropped images, this evaluation is performed on the full 12500×12500 original image. This allows for a direct, head-to-head comparison with the U-Net only model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db62a8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   7%|▋         | 34/483 [00:01<00:10, 43.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Prediction missing: m_2023_RGB_8cm_W24A_17_14_13.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W24A_17_16_18.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  11%|█         | 53/483 [00:01<00:06, 64.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Prediction missing: m_2023_RGB_8cm_W24A_17_18_21.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W24A_17_18_22.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W24A_17_19_13.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  15%|█▌        | 73/483 [00:01<00:05, 76.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Prediction missing: m_2023_RGB_8cm_W24A_17_20_5.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W24A_17_22_1.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  24%|██▎       | 114/483 [00:02<00:05, 64.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Prediction missing: m_2023_RGB_8cm_W24A_17_27_28.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  30%|██▉       | 143/483 [00:02<00:04, 82.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Prediction missing: m_2023_RGB_8cm_W24A_17_30_1.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W24A_17_30_24.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  33%|███▎      | 161/483 [00:03<00:04, 79.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Prediction missing: m_2023_RGB_8cm_W24A_17_32_22.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W24A_17_33_7.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  39%|███▊      | 187/483 [00:03<00:03, 76.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Prediction missing: m_2023_RGB_8cm_W24A_17_35_26.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W24A_17_36_17.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  48%|████▊     | 231/483 [00:04<00:03, 77.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Prediction missing: m_2023_RGB_8cm_W24A_17_3_29.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W24A_17_4_24.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  55%|█████▌    | 268/483 [00:04<00:02, 73.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Prediction missing: m_2023_RGB_8cm_W25C_16_11_25.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W25C_16_12_3.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  59%|█████▉    | 285/483 [00:04<00:02, 70.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Prediction missing: m_2023_RGB_8cm_W25C_16_13_14.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W25C_16_13_25.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W25C_16_13_30.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W25C_16_14_30.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W25C_16_15_10.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W25C_16_15_16.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  64%|██████▍   | 309/483 [00:05<00:01, 92.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Prediction missing: m_2023_RGB_8cm_W25C_16_20_13.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W25C_16_26_11.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W25C_16_26_5.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W25C_16_27_5.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W25C_16_27_9.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W25C_16_29_7.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W25C_16_30_5.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W25C_16_37_10.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  71%|███████   | 341/483 [00:05<00:01, 77.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Prediction missing: m_2023_RGB_8cm_W25C_16_3_15.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W25C_16_6_34.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  75%|███████▍  | 360/483 [00:05<00:01, 78.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Prediction missing: m_2023_RGB_8cm_W25C_16_7_18.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  81%|████████▏ | 393/483 [00:06<00:01, 67.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Prediction missing: m_2023_RGB_8cm_W57B_8_14_13.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W57B_8_18_10.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W57B_8_19_11.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W57B_8_1_27.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  85%|████████▍ | 409/483 [00:06<00:01, 65.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Prediction missing: m_2023_RGB_8cm_W57B_8_1_9.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 483/483 [00:07<00:00, 66.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Prediction missing: m_2023_RGB_8cm_W57B_8_6_32.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W57B_8_7_10.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W57B_8_7_2.png\n",
      "[Warning] Prediction missing: m_2023_RGB_8cm_W57B_8_8_10.png\n",
      "\n",
      " Evaluation saved to metrics_evaluation_YOLO+U-Net.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define class labels\n",
    "CLASSES = [\"background\", \"PV_normal\", \"PV_heater\", \"PV_pool\"]\n",
    "n_classes = len(CLASSES)\n",
    "\n",
    "# Directories for predicted and ground truth masks (as PNGs)\n",
    "pred_dir = \"/shared/data/climateplus2025/YOLO+U-Net_Prediction_3images_updated_head_to_head_comparision_0722/prediction_masks_tiles_320\"\n",
    "gt_dir   = \"/home/cmn60/cape_town_segmentation/masks_320_1k_new\"\n",
    "output_csv = \"metrics_evaluation_YOLO+U-Net.csv\"\n",
    "\n",
    "# Initialize accumulators\n",
    "inter = np.zeros(n_classes, dtype=np.float64)\n",
    "union = np.zeros_like(inter)\n",
    "tp = np.zeros_like(inter)\n",
    "fp = np.zeros_like(inter)\n",
    "fn = np.zeros_like(inter)\n",
    "\n",
    "# Get file list (assuming consistent naming)\n",
    "file_names = sorted([f for f in os.listdir(gt_dir) if f.endswith(\".png\")])\n",
    "\n",
    "for fname in tqdm(file_names, desc=\"Evaluating\"):\n",
    "    gt_path = os.path.join(gt_dir, fname)\n",
    "    pred_path = os.path.join(pred_dir, fname)\n",
    "\n",
    "    if not os.path.exists(pred_path):\n",
    "        print(f\"[Warning] Prediction missing: {fname}\")\n",
    "        continue\n",
    "\n",
    "    # Load grayscale masks (single-channel, values: 0~3)\n",
    "    gt = cv2.imread(gt_path, cv2.IMREAD_GRAYSCALE)\n",
    "    pred = cv2.imread(pred_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if gt.shape != pred.shape:\n",
    "        print(f\"[Error] Shape mismatch: {fname}\")\n",
    "        continue\n",
    "\n",
    "    for cls in range(n_classes):\n",
    "        pred_cls = (pred == cls)\n",
    "        gt_cls   = (gt == cls)\n",
    "\n",
    "        inter[cls] += np.logical_and(pred_cls, gt_cls).sum()\n",
    "        union[cls] += np.logical_or(pred_cls, gt_cls).sum()\n",
    "        tp[cls]    += np.logical_and(pred_cls, gt_cls).sum()\n",
    "        fp[cls]    += np.logical_and(pred_cls, ~gt_cls).sum()\n",
    "        fn[cls]    += np.logical_and(~pred_cls, gt_cls).sum()\n",
    "\n",
    "# Compute metrics\n",
    "eps = 1e-7\n",
    "iou       = (inter + eps) / (union + eps)\n",
    "precision = (tp    + eps) / (tp + fp + eps)\n",
    "recall    = (tp    + eps) / (tp + fn + eps)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"class\": CLASSES,\n",
    "    \"IoU\": iou,\n",
    "    \"Precision\": precision,\n",
    "    \"Recall\": recall\n",
    "})\n",
    "\n",
    "df.to_csv(output_csv, index=False)\n",
    "print(f\"\\n Evaluation saved to {output_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
